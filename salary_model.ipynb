{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('salary_prediction.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>role</th>\n",
       "      <th>employer_industry</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>yearly_compensation</th>\n",
       "      <th>Q11_Part_1</th>\n",
       "      <th>Q11_Part_2</th>\n",
       "      <th>Q11_Part_3</th>\n",
       "      <th>Q11_Part_4</th>\n",
       "      <th>Q11_Part_5</th>\n",
       "      <th>Q11_Part_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>5-10</td>\n",
       "      <td>10-20,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-34</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Other</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22-24</td>\n",
       "      <td>India</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Other</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Academics/Education</td>\n",
       "      <td>10-15</td>\n",
       "      <td>10-20,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18-21</td>\n",
       "      <td>India</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age                   country            role    employer_industry  \\\n",
       "2  30-34                     Other           Other                Other   \n",
       "3  30-34  United States of America  Data Scientist                Other   \n",
       "5  22-24                     India    Data Analyst                Other   \n",
       "7  35-39                     Other           Other  Academics/Education   \n",
       "8  18-21                     India           Other                Other   \n",
       "\n",
       "  years_experience yearly_compensation  Q11_Part_1  Q11_Part_2  Q11_Part_3  \\\n",
       "2             5-10           10-20,000           0           0           0   \n",
       "3              0-1            0-10,000           1           0           0   \n",
       "5              0-1            0-10,000           0           0           0   \n",
       "7            10-15           10-20,000           0           0           0   \n",
       "8              0-1            0-10,000           0           1           0   \n",
       "\n",
       "   Q11_Part_4  Q11_Part_5  Q11_Part_6  \n",
       "2           0           0           1  \n",
       "3           0           0           0  \n",
       "5           0           0           1  \n",
       "7           0           0           1  \n",
       "8           0           0           0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.get_dummies(df[[c for c in df.columns if c != 'yearly_compensation']])\n",
    "target = df.yearly_compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ = ['0-10,000', '10-20,000', '20-30,000', '30-40,000', '40-50,000',\n",
    "         '50-60,000', '60-70,000', '70-80,000', '80-90,000', '90-100,000',\n",
    "         '100-125,000', '125-150,000', '150-200,000', '200-250,000', '>250,000']\n",
    "cat_type = CategoricalDtype(categories=categ, ordered=True)\n",
    "target = target.astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(features, target, base_model, params):\n",
    "    models = []\n",
    "    for i, cat in tqdm.tqdm(enumerate(target.cat.categories[:-1])):\n",
    "    #     print(i, cat, categ[:i + 1], categ[i + 1:])\n",
    "        labels = [0] * len(categ[:i+1]) + [1] * len(categ[i + 1:])\n",
    "        map = {cat: labels[j] for j, cat in enumerate(categ)}\n",
    "        new_target = target.replace(map)\n",
    "        mod = base_model(**params)\n",
    "        mod.fit(features, new_target)\n",
    "        models.append(mod)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:05,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "models = train_models(features, target, LogisticRegression, {\"random_state\": 42, \"solver\": \"lbfgs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('salary_model.pcl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('salary_model.pcl', 'rb') as f:\n",
    "    try_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "prod = lambda x, y: x * y\n",
    "def seq_predict_sample(sample, models):\n",
    "    \"\"\"\n",
    "    Given list of binary classifiers and a sample, predict the most probable category index and the distribution\n",
    "    \"\"\"\n",
    "    binary_probabilities = [mod.predict_proba(sample) for mod in models]\n",
    "    neg_probs = [p[0][0] for p in binary_probabilities]\n",
    "    pos_probs = [p[0][1] for p in binary_probabilities]\n",
    "    bin_probabilities = []\n",
    "    for i in range(len(models)):\n",
    "        bin_prob = [p for p in pos_probs[:i]] + [neg_probs[i]]\n",
    "        reduced = reduce(prod, bin_prob)\n",
    "        bin_probabilities.append(reduced)\n",
    "    bin_probabilities.append(reduce(prod, pos_probs))\n",
    "    return np.argmax(bin_probabilities), bin_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(np.zeros((1, len(cols))), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "q11_map = {\"None of these activities are an important part of my role at work\": \"Q11_Part_6\",\n",
    "           \"Do research that advances the state of the art of machine learning\": \"Q11_Part_5\",\n",
    "           \"Build prototypes to explore applying machine learning to new areas\": \"Q11_Part_4\",\n",
    "           \"Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\": \"Q11_Part_3\",\n",
    "           \"Build and/or run a machine learning service that operationally improves my product or workflows\": \"Q11_Part_2\",\n",
    "           \"Analyze and understand data to influence product or business decisions\": \"Q11_Part_1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(features.columns)\n",
    "def form_input_to_sample(age, country, industry, role, experience, q11):\n",
    "    global cols\n",
    "    sample = pd.DataFrame(np.zeros((1, len(cols))), columns=features.columns)\n",
    "    sample['age_' + age] = 1\n",
    "    sample['country_' + country] = 1\n",
    "    sample['employer_industry_' + industry] = 1\n",
    "    sample['role_' + role] = 1\n",
    "    sample['years_experience_' + experience] = 1\n",
    "    \n",
    "    for value in q11:\n",
    "        sample[q11_map[value]] = 1\n",
    "    return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tf = form_input_to_sample('18-21', 'Brazil', 'Other', 'Student', '>15', ['Do research that advances the state of the art of machine learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [0.7046607899818838,\n",
       "  0.2562497759234744,\n",
       "  0.03838824648734072,\n",
       "  0.0006833248069617659,\n",
       "  1.735696577707625e-05,\n",
       "  4.915676697242235e-07,\n",
       "  1.3585357841939851e-08,\n",
       "  6.445176941933233e-10,\n",
       "  3.428091875728108e-11,\n",
       "  2.5360167291155782e-12,\n",
       "  1.9447067370598507e-13,\n",
       "  5.518411312459705e-15,\n",
       "  1.0884639473254323e-16,\n",
       "  1.522572106228656e-18,\n",
       "  7.698024167015982e-21])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_predict_sample(sample_tf, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
